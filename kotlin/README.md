### 블로킹 작업을 비동기적인 작업의 대기열로 처리했던 경험 & 각종 실험

가급적 구체적인 구현은 숨기고, 전체적인 틀을 보이게끔 정리.

<br>



### Overview

현재까지 떠오르는 실시간 데이터 처리의 유형은 두가지인 듯해보인다.

앞으로 경험이 쌓이게 될때마다 새로운 케이스가 더 추가된다면 종류를 추가할 예정

- 일정시간에 한번씩 합산이 가능한 유형
  - e.g. 
    - 주식 시세(open/high/low/close), 
    - 사람이동 좌표(1초마다 어디에 갔는지), 
    - 자동차 이동 좌표(1초마다 어디에 갔는지)
- 개별 네트워크 호출 각각이 모두 원자적인 데이터가 되어야 하는 경우
  - 이 경우 개별 데이터를 크롤링 하면서 버퍼에 데이터를 쌓아두는 작업자 1개, 쌓아둔 데이터 버퍼를 소비하면서 처리하는 작업자 1\~n개  이렇게 구성하면 될 듯하다.
  - 이 프로젝트에서는 세부적인 구체적 기술내용은 제외할 예정이기에 kafka, rabbitmq 를 이용한 이벤트 처리는 구현이 가려진 가짜 메서드로 대체할 예정
  - e.g. 
    - 코스닥/코스피에 상장된 모든 기업의 개별 실적 데이터 크롤링

<br>



스레드 테스트의 경우 대시보드 모니터링으로는 구체적인 문제점 또는 논리적인 해결점을 찾기 어렵다.

따라서 로컬 도커 기반 레디스를 사용해서 데이터가 저장되었음을 저장하는 방식을 통해 테스트를 진행할 예정

저장결과를 보기위한 결과데이터가 아닌, 성능 측정을 위한 데이터구조를 사용!!

데이터가 몇분 몇초에 저장됐는지 등등 테스트를 위한 객체타입을 지정해서  언제쯤 작업에 지연이 발생했는지를 차트로 표현할 수 있는 자료구조를 만들고, 최소한도의 프론트엔드 개발도 진행해야 할 듯.

<br>



### Experience

- 주식데이터 처리경험 (2022.01 ~ 2022.05)
  - 개별 ppt 문서로 대략적인 처리 구조의 그림을 간단하게 정리
  - ...

<br>



### my study

- 개별 실적 데이터 크롤링 / 데이터 처리





